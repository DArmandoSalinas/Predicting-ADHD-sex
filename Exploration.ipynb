{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Stage 1 - Data Exploration and Preprocessing** *(Fixed)*\n",
    "##### Diego Armando Salinas Lugo  | Student ID: ds24353 / 2401168\n",
    "\n",
    "*Purpose (Fixing Stage 1):*\n",
    "\n",
    "The aim of this notebook is to preprocess the datasets provided for ADHD analysis. The objective is to create a well-structured and clean dataset that can be used in Stage 2 for developing predictive models for both ADHD outcome and Sex.\n",
    "\n",
    "This process involves:\n",
    "- Loading and inspecting datasets.\n",
    "- Splitting the data into training and validation sets.\n",
    "- Handling missing values appropriately.\n",
    "- Performing feature selection and dimensionality reduction where required.\n",
    "- Saving the prepared datasets for Stage 2 modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.experimental import enable_iterative_imputer  \n",
    "from sklearn.impute import KNNImputer, IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: Loading the Datasets**\n",
    "\n",
    "Datasets provided for analysis:\n",
    "\n",
    "- `labels.xlsx` - Contains participant identifiers along with ADHD outcome and Sex.\n",
    "- `metadata_a.xlsx` - Contains numerical metadata for each participant.\n",
    "- `metadata_b.xlsx` - Contains categorical metadata for each participant.\n",
    "- `connectome_matrices.csv` - Contains brain functional connectome matrices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading datasets \n",
    "labels = pd.read_excel(r\"C:\\Users\\Salin\\OneDrive\\Documentos\\ESSEX\\DataScience\\Exploration\\ce888_data_2025\\ce888_data_2025\\Data\\LABELS.xlsx\")  # ADHD diagnosis & sex labels\n",
    "metadata_a = pd.read_excel(r\"C:\\Users\\Salin\\OneDrive\\Documentos\\ESSEX\\DataScience\\Exploration\\ce888_data_2025\\ce888_data_2025\\Data\\METADATA_A.xlsx\")  # Socio-demographic info\n",
    "metadata_b = pd.read_excel(r\"C:\\Users\\Salin\\OneDrive\\Documentos\\ESSEX\\DataScience\\Exploration\\ce888_data_2025\\ce888_data_2025\\Data\\METADATA_B.xlsx\")  # Socio-demographic info\n",
    "connectome_matrices = pd.read_csv(r\"C:\\Users\\Salin\\OneDrive\\Documentos\\ESSEX\\DataScience\\Exploration\\ce888_data_2025\\ce888_data_2025\\Data\\FUNCTIONAL_CONNECTOME_MATRICES.csv\")  # fMRI connectivity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels dataset shape: (1213, 3)\n",
      "Metadata A dataset shape: (1213, 19)\n",
      "Metadata B dataset shape: (1213, 10)\n",
      "Connectome matrices dataset shape: (1213, 19901)\n"
     ]
    }
   ],
   "source": [
    "# Confirming datasets are loaded correctly\n",
    "print(\"Labels dataset shape:\", labels.shape)\n",
    "print(\"Metadata A dataset shape:\", metadata_a.shape)\n",
    "print(\"Metadata B dataset shape:\", metadata_b.shape)\n",
    "print(\"Connectome matrices dataset shape:\", connectome_matrices.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Initial Inspection and Dataset Alignment**\n",
    "\n",
    "The `participant_id` column is the common key across all datasets. This key will be used later for merging the datasets.\n",
    "\n",
    "Before proceeding with splitting and cleaning, the datasets are inspected for consistency in `participant_id`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common key for merging: {'participant_id'}\n",
      "Unique participants in labels: 1213\n",
      "Unique participants in metadata_a: 1213\n",
      "Unique participants in metadata_b: 1213\n",
      "Unique participants in connectome_matrices: 1213\n"
     ]
    }
   ],
   "source": [
    "# Checking common columns for merging later\n",
    "common_key = set(labels.columns) & set(metadata_a.columns) & set(metadata_b.columns) & set(connectome_matrices.columns)\n",
    "print(\"Common key for merging:\", common_key)\n",
    "\n",
    "# Preview of participant IDs in each dataset\n",
    "print(\"Unique participants in labels:\", labels['participant_id'].nunique())\n",
    "print(\"Unique participants in metadata_a:\", metadata_a['participant_id'].nunique())\n",
    "print(\"Unique participants in metadata_b:\", metadata_b['participant_id'].nunique())\n",
    "print(\"Unique participants in connectome_matrices:\", connectome_matrices['participant_id'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Splitting the Data into Training and Validation Sets**\n",
    "\n",
    "The datasets will be splitted into training and validation subsets to prepare for modeling.  \n",
    "Splitting will be stratified by both labels (`ADHD_Outcome` and `Sex_F`) to ensure balanced class representation.\n",
    "\n",
    "*Stratification Approach*\n",
    "\n",
    "As recommended in the assignment feedback, the two labels will be combined into a single categorical variable representing all four possible class combinations:\n",
    "- `0_0` → No ADHD, Male  \n",
    "- `0_1` → No ADHD, Female  \n",
    "- `1_0` → ADHD, Male  \n",
    "- `1_1` → ADHD, Female  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of participants in training set: 970\n",
      "Number of participants in validation set: 243\n"
     ]
    }
   ],
   "source": [
    "# Creating a combined label for stratification\n",
    "labels['combined_label'] = labels['ADHD_Outcome'].astype(str) + \"_\" + labels['Sex_F'].astype(str)\n",
    "\n",
    "# Performing the stratified split\n",
    "train_ids, val_ids = train_test_split(\n",
    "    labels['participant_id'],\n",
    "    test_size=0.2,\n",
    "    stratify=labels['combined_label'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Confirming split sizes\n",
    "print(\"Number of participants in training set:\", len(train_ids))\n",
    "print(\"Number of participants in validation set:\", len(val_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shape: (970, 4)\n",
      "Validation labels shape: (243, 4)\n",
      "Training Metadata A shape: (970, 19)\n",
      "Validation Metadata A shape: (243, 19)\n",
      "Training Metadata B shape: (970, 10)\n",
      "Validation Metadata B shape: (243, 10)\n",
      "Training Connectome shape: (970, 19901)\n",
      "Validation Connectome shape: (243, 19901)\n"
     ]
    }
   ],
   "source": [
    "# Creating training and validation sets for each dataset\n",
    "train_labels = labels[labels['participant_id'].isin(train_ids)].reset_index(drop=True)\n",
    "val_labels = labels[labels['participant_id'].isin(val_ids)].reset_index(drop=True)\n",
    "\n",
    "train_metadata_a = metadata_a[metadata_a['participant_id'].isin(train_ids)].reset_index(drop=True)\n",
    "val_metadata_a = metadata_a[metadata_a['participant_id'].isin(val_ids)].reset_index(drop=True)\n",
    "\n",
    "train_metadata_b = metadata_b[metadata_b['participant_id'].isin(train_ids)].reset_index(drop=True)\n",
    "val_metadata_b = metadata_b[metadata_b['participant_id'].isin(val_ids)].reset_index(drop=True)\n",
    "\n",
    "train_connectome = connectome_matrices[connectome_matrices['participant_id'].isin(train_ids)].reset_index(drop=True)\n",
    "val_connectome = connectome_matrices[connectome_matrices['participant_id'].isin(val_ids)].reset_index(drop=True)\n",
    "\n",
    "# Confirming datasets are aligned after the split\n",
    "print(\"Training labels shape:\", train_labels.shape)\n",
    "print(\"Validation labels shape:\", val_labels.shape)\n",
    "\n",
    "print(\"Training Metadata A shape:\", train_metadata_a.shape)\n",
    "print(\"Validation Metadata A shape:\", val_metadata_a.shape)\n",
    "\n",
    "print(\"Training Metadata B shape:\", train_metadata_b.shape)\n",
    "print(\"Validation Metadata B shape:\", val_metadata_b.shape)\n",
    "\n",
    "print(\"Training Connectome shape:\", train_connectome.shape)\n",
    "print(\"Validation Connectome shape:\", val_connectome.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: Preprocessing Metadata A (Numerical Data)**\n",
    "\n",
    "*4.1 Handling Missing Values*\n",
    "\n",
    "The column `MRI_Track_Age_at_Scan` contains approximately 30% missing values. According to the feedback, an **Iterative Imputer** is recommended instead of using the mean or median. The imputer will be fit on the training data and then applied to the validation set to avoid data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in train_metadata_a_clean: 0\n",
      "Missing values in val_metadata_a_clean: 0\n",
      "Training Metadata A after imputation: (970, 19)\n",
      "Validation Metadata A after imputation: (243, 19)\n"
     ]
    }
   ],
   "source": [
    "# Handling Missing Values with IterativeImputer\n",
    "iterative_imputer = IterativeImputer(random_state=42)\n",
    "\n",
    "# Selecting columns to impute (excluding participant_id)\n",
    "columns_to_impute = train_metadata_a.drop(columns='participant_id').columns\n",
    "\n",
    "# Fitting on training data\n",
    "train_metadata_a_imputed = iterative_imputer.fit_transform(train_metadata_a[columns_to_impute])\n",
    "\n",
    "# Transforming validation data\n",
    "val_metadata_a_imputed = iterative_imputer.transform(val_metadata_a[columns_to_impute])\n",
    "\n",
    "# Converting back to DataFrame and restoring participant_id\n",
    "train_metadata_a_clean = pd.DataFrame(train_metadata_a_imputed, columns=columns_to_impute)\n",
    "train_metadata_a_clean['participant_id'] = train_metadata_a['participant_id']\n",
    "\n",
    "val_metadata_a_clean = pd.DataFrame(val_metadata_a_imputed, columns=columns_to_impute)\n",
    "val_metadata_a_clean['participant_id'] = val_metadata_a['participant_id']\n",
    "\n",
    "# Confirming good executing\n",
    "print(\"Missing values in train_metadata_a_clean:\", train_metadata_a_clean.isnull().sum().sum())\n",
    "print(\"Missing values in val_metadata_a_clean:\", val_metadata_a_clean.isnull().sum().sum())\n",
    "# Confirming shapes\n",
    "print(\"Training Metadata A after imputation:\", train_metadata_a_clean.shape)\n",
    "print(\"Validation Metadata A after imputation:\", val_metadata_a_clean.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*4.2 Feature Selection*\n",
    "\n",
    "Feature selection will be performed using **mutual information** between each numerical feature and the target label `ADHD_Outcome`. Only the features with a mutual information score above a defined threshold will be retained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>MI_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SDQ_SDQ_Hyperactivity</td>\n",
       "      <td>0.163527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SDQ_SDQ_Externalizing</td>\n",
       "      <td>0.154282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SDQ_SDQ_Difficulties_Total</td>\n",
       "      <td>0.127550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SDQ_SDQ_Generating_Impact</td>\n",
       "      <td>0.112013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SDQ_SDQ_Conduct_Problems</td>\n",
       "      <td>0.045341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SDQ_SDQ_Emotional_Problems</td>\n",
       "      <td>0.028967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>APQ_P_APQ_P_ID</td>\n",
       "      <td>0.024279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SDQ_SDQ_Peer_Problems</td>\n",
       "      <td>0.022525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SDQ_SDQ_Internalizing</td>\n",
       "      <td>0.018284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>APQ_P_APQ_P_INV</td>\n",
       "      <td>0.014491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SDQ_SDQ_Prosocial</td>\n",
       "      <td>0.012048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>APQ_P_APQ_P_OPD</td>\n",
       "      <td>0.005478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ColorVision_CV_Score</td>\n",
       "      <td>0.004532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>APQ_P_APQ_P_PP</td>\n",
       "      <td>0.002890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EHQ_EHQ_Total</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>APQ_P_APQ_P_CP</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>APQ_P_APQ_P_PM</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MRI_Track_Age_at_Scan</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Feature  MI_Score\n",
       "13       SDQ_SDQ_Hyperactivity  0.163527\n",
       "11       SDQ_SDQ_Externalizing  0.154282\n",
       "9   SDQ_SDQ_Difficulties_Total  0.127550\n",
       "12   SDQ_SDQ_Generating_Impact  0.112013\n",
       "8     SDQ_SDQ_Conduct_Problems  0.045341\n",
       "10  SDQ_SDQ_Emotional_Problems  0.028967\n",
       "3               APQ_P_APQ_P_ID  0.024279\n",
       "15       SDQ_SDQ_Peer_Problems  0.022525\n",
       "14       SDQ_SDQ_Internalizing  0.018284\n",
       "4              APQ_P_APQ_P_INV  0.014491\n",
       "16           SDQ_SDQ_Prosocial  0.012048\n",
       "5              APQ_P_APQ_P_OPD  0.005478\n",
       "1         ColorVision_CV_Score  0.004532\n",
       "7               APQ_P_APQ_P_PP  0.002890\n",
       "0                EHQ_EHQ_Total  0.000000\n",
       "2               APQ_P_APQ_P_CP  0.000000\n",
       "6               APQ_P_APQ_P_PM  0.000000\n",
       "17       MRI_Track_Age_at_Scan  0.000000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating mutual information scores between features and ADHD_Outcome in training set\n",
    "mi_scores = mutual_info_classif(train_metadata_a_clean.drop(columns='participant_id'),\n",
    "                                train_labels['ADHD_Outcome'],\n",
    "                                discrete_features=False,\n",
    "                                random_state=42)\n",
    "\n",
    "# Creating a DataFrame to view scores\n",
    "mi_scores_df = pd.DataFrame({\n",
    "    'Feature': train_metadata_a_clean.drop(columns='participant_id').columns,\n",
    "    'MI_Score': mi_scores\n",
    "}).sort_values(by='MI_Score', ascending=False)\n",
    "\n",
    "# Displaying mutual information scores\n",
    "mi_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features based on mutual information: ['SDQ_SDQ_Hyperactivity', 'SDQ_SDQ_Externalizing', 'SDQ_SDQ_Difficulties_Total', 'SDQ_SDQ_Generating_Impact', 'SDQ_SDQ_Conduct_Problems', 'SDQ_SDQ_Emotional_Problems', 'APQ_P_APQ_P_ID', 'SDQ_SDQ_Peer_Problems', 'SDQ_SDQ_Internalizing', 'APQ_P_APQ_P_INV', 'SDQ_SDQ_Prosocial']\n",
      "Training Metadata A after feature selection + scaling: (970, 12)\n",
      "Validation Metadata A after feature selection + scaling: (243, 12)\n"
     ]
    }
   ],
   "source": [
    "# Selecting features with MI score above a threshold (MI > 0.01), to work with the more significant features\n",
    "selected_features = mi_scores_df[mi_scores_df['MI_Score'] > 0.01]['Feature'].tolist()\n",
    "\n",
    "print(\"Selected features based on mutual information:\", selected_features)\n",
    "\n",
    "# Extracting only the selected features (excluding participant_id)\n",
    "X_train_a = train_metadata_a_clean[selected_features]\n",
    "X_val_a = val_metadata_a_clean[selected_features]\n",
    "\n",
    "# Standardising numerical features using StandardScaler\n",
    "# This is important because selected Metadata A features are numerical and have different scales.\n",
    "scaler_a = StandardScaler()\n",
    "X_train_a_scaled = scaler_a.fit_transform(X_train_a)\n",
    "X_val_a_scaled = scaler_a.transform(X_val_a)\n",
    "\n",
    "# Reconverting scaled arrays to DataFrames with original feature names\n",
    "X_train_a_scaled_df = pd.DataFrame(X_train_a_scaled, columns=selected_features, index=train_metadata_a_clean.index)\n",
    "X_val_a_scaled_df = pd.DataFrame(X_val_a_scaled, columns=selected_features, index=val_metadata_a_clean.index)\n",
    "\n",
    "# Reattaching participant_id\n",
    "train_metadata_a_selected = pd.concat([X_train_a_scaled_df, train_metadata_a_clean[['participant_id']]], axis=1)\n",
    "val_metadata_a_selected = pd.concat([X_val_a_scaled_df, val_metadata_a_clean[['participant_id']]], axis=1)\n",
    "\n",
    "# Confirming final shapes after selection and scaling\n",
    "print(\"Training Metadata A after feature selection + scaling:\", train_metadata_a_selected.shape)\n",
    "print(\"Validation Metadata A after feature selection + scaling:\", val_metadata_a_selected.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SDQ_SDQ_Hyperactivity</th>\n",
       "      <th>SDQ_SDQ_Externalizing</th>\n",
       "      <th>SDQ_SDQ_Difficulties_Total</th>\n",
       "      <th>SDQ_SDQ_Generating_Impact</th>\n",
       "      <th>SDQ_SDQ_Conduct_Problems</th>\n",
       "      <th>SDQ_SDQ_Emotional_Problems</th>\n",
       "      <th>APQ_P_APQ_P_ID</th>\n",
       "      <th>SDQ_SDQ_Peer_Problems</th>\n",
       "      <th>SDQ_SDQ_Internalizing</th>\n",
       "      <th>APQ_P_APQ_P_INV</th>\n",
       "      <th>SDQ_SDQ_Prosocial</th>\n",
       "      <th>participant_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.888748</td>\n",
       "      <td>0.112626</td>\n",
       "      <td>0.876890</td>\n",
       "      <td>1.043100</td>\n",
       "      <td>-1.010412</td>\n",
       "      <td>1.662304</td>\n",
       "      <td>-0.040638</td>\n",
       "      <td>0.822493</td>\n",
       "      <td>1.512199</td>\n",
       "      <td>-0.860592</td>\n",
       "      <td>-1.197442</td>\n",
       "      <td>CPaeQkhcjg7d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.541133</td>\n",
       "      <td>0.112626</td>\n",
       "      <td>0.281660</td>\n",
       "      <td>0.336531</td>\n",
       "      <td>-0.524252</td>\n",
       "      <td>-0.144346</td>\n",
       "      <td>-0.823800</td>\n",
       "      <td>0.822493</td>\n",
       "      <td>0.395038</td>\n",
       "      <td>-0.699283</td>\n",
       "      <td>0.607560</td>\n",
       "      <td>Nb4EetVPm3gs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.583979</td>\n",
       "      <td>1.996193</td>\n",
       "      <td>1.769735</td>\n",
       "      <td>1.749669</td>\n",
       "      <td>1.906552</td>\n",
       "      <td>0.758979</td>\n",
       "      <td>-0.301692</td>\n",
       "      <td>0.822493</td>\n",
       "      <td>0.953618</td>\n",
       "      <td>-0.054047</td>\n",
       "      <td>-0.746191</td>\n",
       "      <td>p4vPhVu91o4b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.583979</td>\n",
       "      <td>0.818963</td>\n",
       "      <td>0.876890</td>\n",
       "      <td>-0.016754</td>\n",
       "      <td>-0.524252</td>\n",
       "      <td>0.758979</td>\n",
       "      <td>0.481469</td>\n",
       "      <td>0.348166</td>\n",
       "      <td>0.674328</td>\n",
       "      <td>0.107262</td>\n",
       "      <td>0.607560</td>\n",
       "      <td>M09PXs7arQ5E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.888748</td>\n",
       "      <td>1.054409</td>\n",
       "      <td>0.728083</td>\n",
       "      <td>1.749669</td>\n",
       "      <td>0.934230</td>\n",
       "      <td>-1.047670</td>\n",
       "      <td>-0.301692</td>\n",
       "      <td>1.296820</td>\n",
       "      <td>0.115747</td>\n",
       "      <td>-0.699283</td>\n",
       "      <td>-2.099943</td>\n",
       "      <td>tBGXkEdv2cp7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SDQ_SDQ_Hyperactivity  SDQ_SDQ_Externalizing  SDQ_SDQ_Difficulties_Total  \\\n",
       "0               0.888748               0.112626                    0.876890   \n",
       "1               0.541133               0.112626                    0.281660   \n",
       "2               1.583979               1.996193                    1.769735   \n",
       "3               1.583979               0.818963                    0.876890   \n",
       "4               0.888748               1.054409                    0.728083   \n",
       "\n",
       "   SDQ_SDQ_Generating_Impact  SDQ_SDQ_Conduct_Problems  \\\n",
       "0                   1.043100                 -1.010412   \n",
       "1                   0.336531                 -0.524252   \n",
       "2                   1.749669                  1.906552   \n",
       "3                  -0.016754                 -0.524252   \n",
       "4                   1.749669                  0.934230   \n",
       "\n",
       "   SDQ_SDQ_Emotional_Problems  APQ_P_APQ_P_ID  SDQ_SDQ_Peer_Problems  \\\n",
       "0                    1.662304       -0.040638               0.822493   \n",
       "1                   -0.144346       -0.823800               0.822493   \n",
       "2                    0.758979       -0.301692               0.822493   \n",
       "3                    0.758979        0.481469               0.348166   \n",
       "4                   -1.047670       -0.301692               1.296820   \n",
       "\n",
       "   SDQ_SDQ_Internalizing  APQ_P_APQ_P_INV  SDQ_SDQ_Prosocial participant_id  \n",
       "0               1.512199        -0.860592          -1.197442   CPaeQkhcjg7d  \n",
       "1               0.395038        -0.699283           0.607560   Nb4EetVPm3gs  \n",
       "2               0.953618        -0.054047          -0.746191   p4vPhVu91o4b  \n",
       "3               0.674328         0.107262           0.607560   M09PXs7arQ5E  \n",
       "4               0.115747        -0.699283          -2.099943   tBGXkEdv2cp7  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_metadata_a_selected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SDQ_SDQ_Hyperactivity</th>\n",
       "      <th>SDQ_SDQ_Externalizing</th>\n",
       "      <th>SDQ_SDQ_Difficulties_Total</th>\n",
       "      <th>SDQ_SDQ_Generating_Impact</th>\n",
       "      <th>SDQ_SDQ_Conduct_Problems</th>\n",
       "      <th>SDQ_SDQ_Emotional_Problems</th>\n",
       "      <th>APQ_P_APQ_P_ID</th>\n",
       "      <th>SDQ_SDQ_Peer_Problems</th>\n",
       "      <th>SDQ_SDQ_Internalizing</th>\n",
       "      <th>APQ_P_APQ_P_INV</th>\n",
       "      <th>SDQ_SDQ_Prosocial</th>\n",
       "      <th>participant_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.154098</td>\n",
       "      <td>-0.593712</td>\n",
       "      <td>-0.908800</td>\n",
       "      <td>-1.429892</td>\n",
       "      <td>-1.010412</td>\n",
       "      <td>-0.596008</td>\n",
       "      <td>-0.823800</td>\n",
       "      <td>-1.074815</td>\n",
       "      <td>-1.001414</td>\n",
       "      <td>1.236426</td>\n",
       "      <td>1.058810</td>\n",
       "      <td>UmrK0vMLopoR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.888748</td>\n",
       "      <td>0.818963</td>\n",
       "      <td>0.579275</td>\n",
       "      <td>0.689815</td>\n",
       "      <td>0.448070</td>\n",
       "      <td>0.307317</td>\n",
       "      <td>0.481469</td>\n",
       "      <td>-0.126161</td>\n",
       "      <td>0.115747</td>\n",
       "      <td>0.268571</td>\n",
       "      <td>-0.746191</td>\n",
       "      <td>ClMA0FwvFgLY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.888748</td>\n",
       "      <td>1.054409</td>\n",
       "      <td>0.728083</td>\n",
       "      <td>1.043100</td>\n",
       "      <td>0.934230</td>\n",
       "      <td>-0.596008</td>\n",
       "      <td>0.220416</td>\n",
       "      <td>0.822493</td>\n",
       "      <td>0.115747</td>\n",
       "      <td>-0.860592</td>\n",
       "      <td>-1.197442</td>\n",
       "      <td>gZGs9hnN6jiL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.501713</td>\n",
       "      <td>-0.829158</td>\n",
       "      <td>-0.313570</td>\n",
       "      <td>-0.016754</td>\n",
       "      <td>-1.010412</td>\n",
       "      <td>-0.144346</td>\n",
       "      <td>-1.084854</td>\n",
       "      <td>0.822493</td>\n",
       "      <td>0.395038</td>\n",
       "      <td>0.429881</td>\n",
       "      <td>0.607560</td>\n",
       "      <td>Mt3Yj75IxPWc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.193518</td>\n",
       "      <td>0.583517</td>\n",
       "      <td>0.728083</td>\n",
       "      <td>0.336531</td>\n",
       "      <td>0.934230</td>\n",
       "      <td>1.662304</td>\n",
       "      <td>1.003577</td>\n",
       "      <td>-0.600488</td>\n",
       "      <td>0.674328</td>\n",
       "      <td>-0.537974</td>\n",
       "      <td>-2.099943</td>\n",
       "      <td>HCoutm3vtxtD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SDQ_SDQ_Hyperactivity  SDQ_SDQ_Externalizing  SDQ_SDQ_Difficulties_Total  \\\n",
       "0              -0.154098              -0.593712                   -0.908800   \n",
       "1               0.888748               0.818963                    0.579275   \n",
       "2               0.888748               1.054409                    0.728083   \n",
       "3              -0.501713              -0.829158                   -0.313570   \n",
       "4               0.193518               0.583517                    0.728083   \n",
       "\n",
       "   SDQ_SDQ_Generating_Impact  SDQ_SDQ_Conduct_Problems  \\\n",
       "0                  -1.429892                 -1.010412   \n",
       "1                   0.689815                  0.448070   \n",
       "2                   1.043100                  0.934230   \n",
       "3                  -0.016754                 -1.010412   \n",
       "4                   0.336531                  0.934230   \n",
       "\n",
       "   SDQ_SDQ_Emotional_Problems  APQ_P_APQ_P_ID  SDQ_SDQ_Peer_Problems  \\\n",
       "0                   -0.596008       -0.823800              -1.074815   \n",
       "1                    0.307317        0.481469              -0.126161   \n",
       "2                   -0.596008        0.220416               0.822493   \n",
       "3                   -0.144346       -1.084854               0.822493   \n",
       "4                    1.662304        1.003577              -0.600488   \n",
       "\n",
       "   SDQ_SDQ_Internalizing  APQ_P_APQ_P_INV  SDQ_SDQ_Prosocial participant_id  \n",
       "0              -1.001414         1.236426           1.058810   UmrK0vMLopoR  \n",
       "1               0.115747         0.268571          -0.746191   ClMA0FwvFgLY  \n",
       "2               0.115747        -0.860592          -1.197442   gZGs9hnN6jiL  \n",
       "3               0.395038         0.429881           0.607560   Mt3Yj75IxPWc  \n",
       "4               0.674328        -0.537974          -2.099943   HCoutm3vtxtD  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metadata_a_selected.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5: Preprocessing Metadata B (Categorical Data)**\n",
    "\n",
    "*5.1 Handling Missing Values*\n",
    "\n",
    "The column `PreInt_Demos_Fam_Child_Ethnicity` contains missing values. According to the provided data dictionary and assignment feedback, missing values in this column should be filled with `3`, which represents 'Unknown'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column data types (train):\n",
      "Basic_Demos_Enroll_Year             category\n",
      "Basic_Demos_Study_Site              category\n",
      "PreInt_Demos_Fam_Child_Ethnicity    category\n",
      "PreInt_Demos_Fam_Child_Race         category\n",
      "MRI_Track_Scan_Location             category\n",
      "Barratt_Barratt_P1_Edu              category\n",
      "Barratt_Barratt_P1_Occ              category\n",
      "Barratt_Barratt_P2_Edu              category\n",
      "Barratt_Barratt_P2_Occ              category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Handling missing values\n",
    "# Copies to avoid problems in original data\n",
    "train_metadata_b_clean = train_metadata_b.copy()\n",
    "val_metadata_b_clean = val_metadata_b.copy()\n",
    "\n",
    "ethnicity_col = 'PreInt_Demos_Fam_Child_Ethnicity'\n",
    "\n",
    "# Filling missing values with 3 (\"Unknown\")\n",
    "train_metadata_b_clean[ethnicity_col] = train_metadata_b_clean[ethnicity_col].fillna(3)\n",
    "val_metadata_b_clean[ethnicity_col] = val_metadata_b_clean[ethnicity_col].fillna(3)\n",
    "\n",
    "# Ensuring all feature columns are treated as categorical\n",
    "b_feature_columns = train_metadata_b_clean.drop(columns='participant_id').columns\n",
    "\n",
    "for col in b_feature_columns:\n",
    "    train_metadata_b_clean[col] = train_metadata_b_clean[col].astype('category')\n",
    "    val_metadata_b_clean[col] = val_metadata_b_clean[col].astype('category')\n",
    "\n",
    "# Confirming all columns are now categorical\n",
    "print(\"Column data types (train):\")\n",
    "print(train_metadata_b_clean[b_feature_columns].dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*5.2 Feature Selection*\n",
    "\n",
    "Feature selection for categorical data is performed using **Mutual Information**, which measures the dependency between each feature and the target `ADHD_Outcome`. All features are treated as discrete (categorical), as required for accurate analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>MI_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Basic_Demos_Enroll_Year</td>\n",
       "      <td>0.020455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MRI_Track_Scan_Location</td>\n",
       "      <td>0.014061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PreInt_Demos_Fam_Child_Race</td>\n",
       "      <td>0.005071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Barratt_Barratt_P1_Occ</td>\n",
       "      <td>0.004937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Basic_Demos_Study_Site</td>\n",
       "      <td>0.002598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Barratt_Barratt_P2_Occ</td>\n",
       "      <td>0.001855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Barratt_Barratt_P1_Edu</td>\n",
       "      <td>0.001620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Barratt_Barratt_P2_Edu</td>\n",
       "      <td>0.000938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PreInt_Demos_Fam_Child_Ethnicity</td>\n",
       "      <td>0.000814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Feature  MI_Score\n",
       "0           Basic_Demos_Enroll_Year  0.020455\n",
       "4           MRI_Track_Scan_Location  0.014061\n",
       "3       PreInt_Demos_Fam_Child_Race  0.005071\n",
       "6            Barratt_Barratt_P1_Occ  0.004937\n",
       "1            Basic_Demos_Study_Site  0.002598\n",
       "8            Barratt_Barratt_P2_Occ  0.001855\n",
       "5            Barratt_Barratt_P1_Edu  0.001620\n",
       "7            Barratt_Barratt_P2_Edu  0.000938\n",
       "2  PreInt_Demos_Fam_Child_Ethnicity  0.000814"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating mutual information scores\n",
    "mi_scores_b = mutual_info_classif(\n",
    "    train_metadata_b_clean[b_feature_columns],\n",
    "    train_labels['ADHD_Outcome'],\n",
    "    discrete_features=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Creating DataFrame of MI scores\n",
    "mi_scores_b_df = pd.DataFrame({\n",
    "    'Feature': b_feature_columns,\n",
    "    'MI_Score': mi_scores_b\n",
    "}).sort_values(by='MI_Score', ascending=False)\n",
    "\n",
    "# Displaying MI scores\n",
    "mi_scores_b_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features from Metadata B: ['Basic_Demos_Enroll_Year', 'MRI_Track_Scan_Location']\n",
      "Training Metadata B after feature selection: (970, 3)\n",
      "Validation Metadata B after feature selection: (243, 3)\n"
     ]
    }
   ],
   "source": [
    "# Selecting features with mutual information score above threshold\n",
    "selected_features_b = mi_scores_b_df[mi_scores_b_df['MI_Score'] > 0.01]['Feature'].tolist()\n",
    "\n",
    "print(\"Selected features from Metadata B:\", selected_features_b)\n",
    "\n",
    "# Creating reduced datasets\n",
    "train_metadata_b_selected = train_metadata_b_clean[selected_features_b + ['participant_id']]\n",
    "val_metadata_b_selected = val_metadata_b_clean[selected_features_b + ['participant_id']]\n",
    "\n",
    "# Confirming final shapes\n",
    "print(\"Training Metadata B after feature selection:\", train_metadata_b_selected.shape)\n",
    "print(\"Validation Metadata B after feature selection:\", val_metadata_b_selected.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6: Preprocessing Brain Connectome Data**\n",
    "\n",
    "The connectome dataset contains numerical values representing brain connectivity features for each participant.\n",
    "\n",
    "*6.1 Checking for Missing Values*\n",
    "\n",
    "According to the feedback, this dataset does not contain missing values. A final check is performed to confirm this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in training connectome: 0\n",
      "Missing values in validation connectome: 0\n"
     ]
    }
   ],
   "source": [
    "# Checking for missing values in training and validation connectome datasets\n",
    "print(\"Missing values in training connectome:\", train_connectome.isnull().sum().sum())\n",
    "print(\"Missing values in validation connectome:\", val_connectome.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*6.2 Standardisation*\n",
    "\n",
    "The connectome features must be standardised before applying dimensionality reduction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping participant_id temporarily\n",
    "connectome_features = train_connectome.drop(columns='participant_id').columns\n",
    "\n",
    "# Initialising and fitting scaler on training data\n",
    "scaler = StandardScaler()\n",
    "train_connectome_scaled = scaler.fit_transform(train_connectome[connectome_features])\n",
    "val_connectome_scaled = scaler.transform(val_connectome[connectome_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*6.3 Dimensionality Reduction with KernelPCA*\n",
    "\n",
    "KernelPCA is used instead of traditional PCA, as the connectome features are typically uncorrelated and KernelPCA can better capture complex non-linear structures. A radial basis function (RBF) kernel is used (to capture complex patterns), and the number of components is initially set to 100 (arbitrary for now)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced training connectome shape: (970, 101)\n",
      "Reduced validation connectome shape: (243, 101)\n"
     ]
    }
   ],
   "source": [
    "# Applying KernelPCA with RBF kernel\n",
    "kernel_pca = KernelPCA(n_components=100, kernel='rbf', random_state=42)\n",
    "\n",
    "# Fitting and transforming training data\n",
    "train_connectome_reduced = kernel_pca.fit_transform(train_connectome_scaled)\n",
    "\n",
    "# Transforming validation data using the same transformation\n",
    "val_connectome_reduced = kernel_pca.transform(val_connectome_scaled)\n",
    "\n",
    "# Converting to DataFrames and reattaching participant_id\n",
    "train_connectome_reduced_df = pd.DataFrame(train_connectome_reduced, \n",
    "                                            columns=[f'kpc_{i+1}' for i in range(train_connectome_reduced.shape[1])])\n",
    "train_connectome_reduced_df['participant_id'] = train_connectome['participant_id'].values\n",
    "\n",
    "val_connectome_reduced_df = pd.DataFrame(val_connectome_reduced, \n",
    "                                          columns=[f'kpc_{i+1}' for i in range(val_connectome_reduced.shape[1])])\n",
    "val_connectome_reduced_df['participant_id'] = val_connectome['participant_id'].values\n",
    "\n",
    "# Confirming final shapes\n",
    "print(\"Reduced training connectome shape:\", train_connectome_reduced_df.shape)\n",
    "print(\"Reduced validation connectome shape:\", val_connectome_reduced_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 7: Merging All Cleaned Datasets and Saving Final Files**\n",
    "\n",
    "This final step merges the cleaned versions of all datasets into one final training and one final validation dataset, using `participant_id` as the join key.\n",
    "\n",
    "Each of the following preprocessed components will be included:\n",
    "- Metadata A (numerical features)\n",
    "- Metadata B (categorical features)\n",
    "- Brain Connectome (dimensionality-reduced features)\n",
    "- Labels (`ADHD_Outcome` and `Sex_F`)\n",
    "\n",
    "After merging, the resulting datasets will be saved as CSV files to be used in Stage 2 for model development.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training dataset shape: (970, 117)\n",
      "Final validation dataset shape: (243, 117)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>SDQ_SDQ_Hyperactivity</th>\n",
       "      <th>SDQ_SDQ_Externalizing</th>\n",
       "      <th>SDQ_SDQ_Difficulties_Total</th>\n",
       "      <th>SDQ_SDQ_Generating_Impact</th>\n",
       "      <th>SDQ_SDQ_Conduct_Problems</th>\n",
       "      <th>SDQ_SDQ_Emotional_Problems</th>\n",
       "      <th>APQ_P_APQ_P_ID</th>\n",
       "      <th>SDQ_SDQ_Peer_Problems</th>\n",
       "      <th>SDQ_SDQ_Internalizing</th>\n",
       "      <th>...</th>\n",
       "      <th>kpc_94</th>\n",
       "      <th>kpc_95</th>\n",
       "      <th>kpc_96</th>\n",
       "      <th>kpc_97</th>\n",
       "      <th>kpc_98</th>\n",
       "      <th>kpc_99</th>\n",
       "      <th>kpc_100</th>\n",
       "      <th>ADHD_Outcome</th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>combined_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CPaeQkhcjg7d</td>\n",
       "      <td>0.888748</td>\n",
       "      <td>0.112626</td>\n",
       "      <td>0.876890</td>\n",
       "      <td>1.043100</td>\n",
       "      <td>-1.010412</td>\n",
       "      <td>1.662304</td>\n",
       "      <td>-0.040638</td>\n",
       "      <td>0.822493</td>\n",
       "      <td>1.512199</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018947</td>\n",
       "      <td>0.015052</td>\n",
       "      <td>0.014926</td>\n",
       "      <td>0.026043</td>\n",
       "      <td>0.013216</td>\n",
       "      <td>-0.000928</td>\n",
       "      <td>0.004189</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nb4EetVPm3gs</td>\n",
       "      <td>0.541133</td>\n",
       "      <td>0.112626</td>\n",
       "      <td>0.281660</td>\n",
       "      <td>0.336531</td>\n",
       "      <td>-0.524252</td>\n",
       "      <td>-0.144346</td>\n",
       "      <td>-0.823800</td>\n",
       "      <td>0.822493</td>\n",
       "      <td>0.395038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.038887</td>\n",
       "      <td>0.040289</td>\n",
       "      <td>0.091698</td>\n",
       "      <td>0.009369</td>\n",
       "      <td>0.047024</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p4vPhVu91o4b</td>\n",
       "      <td>1.583979</td>\n",
       "      <td>1.996193</td>\n",
       "      <td>1.769735</td>\n",
       "      <td>1.749669</td>\n",
       "      <td>1.906552</td>\n",
       "      <td>0.758979</td>\n",
       "      <td>-0.301692</td>\n",
       "      <td>0.822493</td>\n",
       "      <td>0.953618</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014591</td>\n",
       "      <td>-0.010950</td>\n",
       "      <td>0.021610</td>\n",
       "      <td>0.007125</td>\n",
       "      <td>-0.007026</td>\n",
       "      <td>-0.034629</td>\n",
       "      <td>-0.020219</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M09PXs7arQ5E</td>\n",
       "      <td>1.583979</td>\n",
       "      <td>0.818963</td>\n",
       "      <td>0.876890</td>\n",
       "      <td>-0.016754</td>\n",
       "      <td>-0.524252</td>\n",
       "      <td>0.758979</td>\n",
       "      <td>0.481469</td>\n",
       "      <td>0.348166</td>\n",
       "      <td>0.674328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040847</td>\n",
       "      <td>-0.006969</td>\n",
       "      <td>-0.001195</td>\n",
       "      <td>0.021064</td>\n",
       "      <td>-0.023642</td>\n",
       "      <td>0.004738</td>\n",
       "      <td>-0.052029</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tBGXkEdv2cp7</td>\n",
       "      <td>0.888748</td>\n",
       "      <td>1.054409</td>\n",
       "      <td>0.728083</td>\n",
       "      <td>1.749669</td>\n",
       "      <td>0.934230</td>\n",
       "      <td>-1.047670</td>\n",
       "      <td>-0.301692</td>\n",
       "      <td>1.296820</td>\n",
       "      <td>0.115747</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010181</td>\n",
       "      <td>-0.014564</td>\n",
       "      <td>-0.024268</td>\n",
       "      <td>-0.051242</td>\n",
       "      <td>0.022815</td>\n",
       "      <td>-0.028150</td>\n",
       "      <td>0.025366</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant_id  SDQ_SDQ_Hyperactivity  SDQ_SDQ_Externalizing  \\\n",
       "0   CPaeQkhcjg7d               0.888748               0.112626   \n",
       "1   Nb4EetVPm3gs               0.541133               0.112626   \n",
       "2   p4vPhVu91o4b               1.583979               1.996193   \n",
       "3   M09PXs7arQ5E               1.583979               0.818963   \n",
       "4   tBGXkEdv2cp7               0.888748               1.054409   \n",
       "\n",
       "   SDQ_SDQ_Difficulties_Total  SDQ_SDQ_Generating_Impact  \\\n",
       "0                    0.876890                   1.043100   \n",
       "1                    0.281660                   0.336531   \n",
       "2                    1.769735                   1.749669   \n",
       "3                    0.876890                  -0.016754   \n",
       "4                    0.728083                   1.749669   \n",
       "\n",
       "   SDQ_SDQ_Conduct_Problems  SDQ_SDQ_Emotional_Problems  APQ_P_APQ_P_ID  \\\n",
       "0                 -1.010412                    1.662304       -0.040638   \n",
       "1                 -0.524252                   -0.144346       -0.823800   \n",
       "2                  1.906552                    0.758979       -0.301692   \n",
       "3                 -0.524252                    0.758979        0.481469   \n",
       "4                  0.934230                   -1.047670       -0.301692   \n",
       "\n",
       "   SDQ_SDQ_Peer_Problems  SDQ_SDQ_Internalizing  ...    kpc_94    kpc_95  \\\n",
       "0               0.822493               1.512199  ... -0.018947  0.015052   \n",
       "1               0.822493               0.395038  ...  0.000298  0.024330   \n",
       "2               0.822493               0.953618  ... -0.014591 -0.010950   \n",
       "3               0.348166               0.674328  ...  0.040847 -0.006969   \n",
       "4               1.296820               0.115747  ... -0.010181 -0.014564   \n",
       "\n",
       "     kpc_96    kpc_97    kpc_98    kpc_99   kpc_100  ADHD_Outcome  Sex_F  \\\n",
       "0  0.014926  0.026043  0.013216 -0.000928  0.004189             1      0   \n",
       "1  0.038887  0.040289  0.091698  0.009369  0.047024             1      0   \n",
       "2  0.021610  0.007125 -0.007026 -0.034629 -0.020219             1      1   \n",
       "3 -0.001195  0.021064 -0.023642  0.004738 -0.052029             1      1   \n",
       "4 -0.024268 -0.051242  0.022815 -0.028150  0.025366             1      0   \n",
       "\n",
       "   combined_label  \n",
       "0             1_0  \n",
       "1             1_0  \n",
       "2             1_1  \n",
       "3             1_1  \n",
       "4             1_0  \n",
       "\n",
       "[5 rows x 117 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging all training components on 'participant_id'\n",
    "train_merged = (\n",
    "    train_labels\n",
    "    .merge(train_metadata_a_selected, on='participant_id')\n",
    "    .merge(train_metadata_b_selected, on='participant_id')\n",
    "    .merge(train_connectome_reduced_df, on='participant_id')\n",
    ")\n",
    "\n",
    "# Merging all validation components\n",
    "val_merged = (\n",
    "    val_labels\n",
    "    .merge(val_metadata_a_selected, on='participant_id')\n",
    "    .merge(val_metadata_b_selected, on='participant_id')\n",
    "    .merge(val_connectome_reduced_df, on='participant_id')\n",
    ")\n",
    "\n",
    "# Reordering columns: participant_id first, features in the middle, labels at the end (for easier management in Modelling)\n",
    "def reorder_columns(df):\n",
    "    # Starting with participant_id\n",
    "    cols = ['participant_id']\n",
    "    \n",
    "    # Finding label columns\n",
    "    label_cols = ['ADHD_Outcome', 'Sex_F', 'combined_label']\n",
    "    \n",
    "    # Getting all other columns(features)\n",
    "    feature_cols = [col for col in df.columns if col not in cols + label_cols]\n",
    "    \n",
    "    # Final column order\n",
    "    return df[cols + feature_cols + label_cols]\n",
    "\n",
    "# Applying reordering\n",
    "train_merged = reorder_columns(train_merged)\n",
    "val_merged = reorder_columns(val_merged)\n",
    "\n",
    "# Confirming final structure\n",
    "print(\"Final training dataset shape:\", train_merged.shape)\n",
    "print(\"Final validation dataset shape:\", val_merged.shape)\n",
    "train_merged.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned datasets saved as 'cleaned_train_data.csv' and 'cleaned_validation_data.csv'\n"
     ]
    }
   ],
   "source": [
    "# Saving cleaned datasets to CSV\n",
    "train_merged.to_csv('cleaned_train_data.csv', index=False)\n",
    "val_merged.to_csv('cleaned_validation_data.csv', index=False)\n",
    "\n",
    "print(\"Cleaned datasets saved as 'cleaned_train_data.csv' and 'cleaned_validation_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 8: Plan for Stage 2 (Model Development)**\n",
    "\n",
    "In Stage 2, the objective will be to train predictive models for the two labels: `ADHD_Outcome` and `Sex_F`, using the cleaned and preprocessed dataset prepared in Stage 1.\n",
    "\n",
    "*8.1 Target Variables*\n",
    "\n",
    "The final dataset includes two classification labels:\n",
    "- `ADHD_Outcome` (binary classification)\n",
    "- `Sex_F` (binary classification)\n",
    "\n",
    "*8.2 Candidate Models*\n",
    "\n",
    "A variety of classification models will be considered:\n",
    "- **Logistic Regression**\n",
    "- **Random Forest Classifier**\n",
    "- **Support Vector Machines (SVM)**\n",
    "- **K-Nearest Neighbors (KNN)**\n",
    "- **Gradient Boosting (e.g., XGBoost)**\n",
    "- **Multi-layer Perceptron (Neural Networks)**\n",
    "\n",
    "*8.3 Evaluation Metrics*\n",
    "\n",
    "Since both labels are binary, the following metrics will be used to evaluate model performance:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 Score\n",
    "- Area Under the ROC Curve (AUC-ROC)\n",
    "\n",
    "Metrics will be reported on both the training and validation sets.\n",
    "\n",
    "*8.4 Hyperparameter Tuning*\n",
    "\n",
    "- **Grid Search** and/or **Random Search**\n",
    "- **Cross-Validation** (e.g., 5-fold stratified)\n",
    "\n",
    "*8.5 Bias and Fairness*\n",
    "\n",
    "The potential for model bias will be evaluated, especially regarding:\n",
    "- Gender (`Sex_F`)\n",
    "- Data imbalance\n",
    "\n",
    "*8.6 Interpretability*\n",
    "\n",
    "Model interpretability will be addressed considering the use of:\n",
    "- **Feature importance** (tree-based models)\n",
    "- **Permutation importance**\n",
    "- **SHAP values** (for complex models like XGBoost or MLP)\n",
    "- **LIME**\n",
    "\n",
    "Interpretability is essential to ensure the models offer transparent, explainable predictions in a health-related context."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
